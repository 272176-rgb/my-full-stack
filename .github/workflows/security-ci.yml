name: Security CI (SAST + SCA + DAST)

on:
  push:
    branches: [ master, main ]
  pull_request:
    types: [ opened, synchronize, reopened ]
  workflow_dispatch: {}

concurrency:
  group: security-ci-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  security-events: write
  actions: read

env:
  FRONT_URL: http://localhost:5173
  API_OPENAPI_URL: http://localhost:8000/api/v1/openapi.json
  DOCKER_BUILDKIT: "1"

defaults:
  run:
    shell: bash

jobs:
  sast_sca:
    name: SAST + SCA
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Prepare reports dir
        run: mkdir -p reports/sast reports/sca

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: |
            frontend/package-lock.json
            frontend/package.json

      # -------- SAST: Semgrep --------
      - name: Semgrep (SAST)
        continue-on-error: true
        uses: returntocorp/semgrep-action@v1
        with:
          config: |
            p/owasp-top-ten
            p/ci
          generateSarif: "1"

      - name: Upload Semgrep SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep.sarif

      - name: Collect Semgrep report
        if: always()
        run: |
          cp -f semgrep.sarif reports/sast/semgrep.sarif 2>/dev/null || true

      # -------- SAST: Bandit --------
      - name: Install Bandit
        continue-on-error: true
        run: pipx install bandit || pip install bandit

      - name: Run Bandit (backend)
        continue-on-error: true
        run: bandit -r backend -ll -iii -f json -o bandit.json

      - name: Collect Bandit report
        if: always()
        run: |
          cp -f bandit.json reports/sast/bandit.json 2>/dev/null || true

      # -------- SCA: Trivy (repo) -> SARIF --------
      - name: Trivy FS (SCA + misconfig + secrets)
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          scan-type: fs
          scan-ref: .
          ignore-unfixed: true
          severity: HIGH,CRITICAL
          format: sarif
          output: trivy-repo.sarif

      - name: Upload Trivy SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-repo.sarif

      - name: Collect Trivy SARIF
        if: always()
        run: |
          cp -f trivy-repo.sarif reports/sca/trivy-repo.sarif 2>/dev/null || true

      # -------- SBOM: Trivy (CycloneDX) --------
      - name: Trivy SBOM (CycloneDX)
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          scan-type: fs
          scan-ref: .
          args: --format cyclonedx --output sbom.cdx.json

      - name: Collect SBOM
        if: always()
        run: |
          cp -f sbom.cdx.json reports/sca/sbom.cyclonedx.json 2>/dev/null || true

      # -------- SCA: Python (pip-audit) --------
      - name: Install pip-audit
        continue-on-error: true
        run: pipx install pip-audit || pip install pip-audit

      - name: pip-audit (backend)
        continue-on-error: true
        run: |
          if [ -f backend/requirements.txt ]; then
            pip-audit -r backend/requirements.txt -f json -o pip-audit.json
          else
            echo '{}' > pip-audit.json
          fi

      - name: Collect pip-audit report
        if: always()
        run: |
          cp -f pip-audit.json reports/sca/pip-audit.json 2>/dev/null || true

      # -------- Frontend: lint + npm audit --------
      - name: Frontend install
        if: hashFiles('frontend/package.json') != ''
        continue-on-error: true
        working-directory: frontend
        run: npm ci

      - name: Frontend lint
        if: hashFiles('frontend/package.json') != ''
        continue-on-error: true
        working-directory: frontend
        run: npm run lint

      - name: npm audit (high+)
        if: hashFiles('frontend/package.json') != ''
        continue-on-error: true
        working-directory: frontend
        run: npm audit --audit-level=high --json > ../npm-audit.json

      - name: Collect npm-audit
        if: always() && hashFiles('frontend/package.json') != ''
        run: |
          cp -f npm-audit.json reports/sca/npm-audit.json 2>/dev/null || true

      # ---- Upload ONE artifact with everything from this job ----
      - name: Upload consolidated reports (SAST/SCA)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: reports/**
          if-no-files-found: ignore
          retention-days: 14

  build_and_dast:
    name: DAST (ZAP) — start app only for tests (uv)
    runs-on: ubuntu-latest
    needs: [sast_sca]
    timeout-minutes: 45

    services:
      postgres:
        image: postgres:17
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: changethis
          POSTGRES_DB: app
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d app"
          --health-interval=10s --health-timeout=5s --health-retries=10

    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Prepare reports dir
        run: mkdir -p reports/dast

      # ---- Install uv (jak w Dockerfile) + cache ----
      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Cache uv downloads
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: uv-${{ runner.os }}-${{ hashFiles('**/pyproject.toml', '**/uv.lock') }}
          restore-keys: |
            uv-${{ runner.os }}-

      # ---- ENV na czas DAST (zgodne z Pydantic v2 + brakujące pola) ----
      - name: Prepare runtime env
        run: |
          echo 'DOMAIN=localhost' >> $GITHUB_ENV
          echo 'FRONTEND_HOST=http://localhost:5173' >> $GITHUB_ENV
          echo 'ENVIRONMENT=local' >> $GITHUB_ENV
          echo 'BACKEND_CORS_ORIGINS=["http://localhost:5173","http://127.0.0.1:5173","http://localhost"]' >> $GITHUB_ENV
          echo 'SECRET_KEY=dev-secret' >> $GITHUB_ENV
          echo 'FIRST_SUPERUSER=272176@gr.pl' >> $GITHUB_ENV
          echo 'FIRST_SUPERUSER_PASSWORD=StrongPassw0rd!' >> $GITHUB_ENV
          echo 'PROJECT_NAME=app' >> $GITHUB_ENV
          echo 'POSTGRES_SERVER=localhost' >> $GITHUB_ENV
          echo 'POSTGRES_PORT=5432' >> $GITHUB_ENV
          echo 'POSTGRES_DB=app' >> $GITHUB_ENV
          echo 'POSTGRES_USER=postgres' >> $GITHUB_ENV
          echo 'POSTGRES_PASSWORD=changethis' >> $GITHUB_ENV
          echo 'SMTP_HOST=' >> $GITHUB_ENV
          echo 'SMTP_USER=' >> $GITHUB_ENV
          echo 'SMTP_PASSWORD=' >> $GITHUB_ENV
          echo 'EMAILS_FROM_EMAIL=info@example.com' >> $GITHUB_ENV
          echo 'SENTRY_DSN=' >> $GITHUB_ENV

      # ---- Sync deps i prestart (migracje) ----
      - name: uv sync (backend)
        working-directory: backend
        run: uv sync

      - name: Prestart script (optional)
        working-directory: backend
        run: |
          if [ -f scripts/prestart.sh ]; then
            uv run bash scripts/prestart.sh || true
          fi

      # ---- Start backend i czekaj na health ----
      - name: Start backend (fastapi run via uv)
        working-directory: backend
        env:
          DOMAIN: ${{ env.DOMAIN }}
          FRONTEND_HOST: ${{ env.FRONTEND_HOST }}
          ENVIRONMENT: ${{ env.ENVIRONMENT }}
          BACKEND_CORS_ORIGINS: ${{ env.BACKEND_CORS_ORIGINS }}
          SECRET_KEY: ${{ env.SECRET_KEY }}
          FIRST_SUPERUSER: ${{ env.FIRST_SUPERUSER }}
          FIRST_SUPERUSER_PASSWORD: ${{ env.FIRST_SUPERUSER_PASSWORD }}
          POSTGRES_SERVER: ${{ env.POSTGRES_SERVER }}
          POSTGRES_PORT: ${{ env.POSTGRES_PORT }}
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          SENTRY_DSN: ${{ env.SENTRY_DSN }}
          PROJECT_NAME: ${{ env.PROJECT_NAME }}
        run: |
          nohup uv run fastapi run app/main.py --host 0.0.0.0 --port 8000 --workers 4 > ../backend.log 2>&1 & echo $! > ../backend.pid

      - name: Wait for backend health
        run: |
          for i in {1..60}; do
            curl -fsS http://localhost:8000/api/v1/utils/health-check/ && exit 0
            sleep 2
          done
          echo "Backend not healthy"
          echo "---- backend.log ----"
          tail -n 200 backend.log || true
          exit 1

      # ---- ZAP DAST (API Scan) ----
      - name: Pre-pull ZAP image
        run: docker pull ghcr.io/zaproxy/zaproxy:stable

      - name: ZAP API Scan (backend OpenAPI) — host network
        run: |
          set -e
          # podejście 1: host network (najprostsze na GH-hosted Linux runners)
          docker run --rm -t --network host \
            -v "$PWD:/zap/wrk" -w /zap/wrk \
            ghcr.io/zaproxy/zaproxy:stable \
            zap-api-scan.py \
              -t "http://127.0.0.1:8000/api/v1/openapi.json" \
              -f openapi \
              -m 15 \
              -r zap-api.html | tee zap-api.log

      - name: ZAP API Scan (backend OpenAPI)
        run: |
          docker run --rm -t -u zap \
            -v "$PWD:/zap/wrk" -w /zap/wrk \
            ghcr.io/zaproxy/zaproxy:stable \
            zap-api-scan.py \
              -t "${{ env.API_OPENAPI_URL }}" \
              -f openapi \
              -m 15 \
              -r zap-api.html | tee zap-api.log

      # ---- (opcjonalnie) fail przy High ----
      - name: Enforce thresholds (fail on HIGH)
        if: always()
        run: |
          fail=0
          grep -Eiq "High Alert|Risk: High" zap-api.log && echo "ZAP API: High found" && fail=1 || true
          if [ $fail -ne 0 ]; then exit 1; fi

      - name: Collect ZAP reports
        if: always()
        run: |
          mkdir -p reports/dast
          [ -f zap-api.html ] && cp -f zap-api.html reports/dast/zap-api.html || true
          [ -f zap-api.log ] && cp -f zap-api.log reports/dast/zap-api.log || true
          [ -f backend.log ] && cp -f backend.log reports/dast/backend.log || true

      # ---- Teardown backend (działał tylko na czas DAST) ----
      - name: Stop backend
        if: always()
        run: |
          if [ -f backend.pid ]; then
            kill -9 "$(cat backend.pid)" 2>/dev/null || true
          fi

      # ---- Upload to the SAME artifact name (merge with SAST/SCA) ----
      - name: Upload consolidated reports (DAST)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: reports/**
          if-no-files-found: ignore
          retention-days: 14
          overwrite: true
