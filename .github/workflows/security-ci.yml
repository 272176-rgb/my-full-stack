name: Security CI (SAST + SCA + DAST)

on:
  push:
    branches: [ master, main ]
  pull_request:
    types: [ opened, synchronize, reopened ]
  workflow_dispatch: {}

concurrency:
  group: security-ci-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  security-events: write
  actions: read

env:
  FRONT_URL: http://localhost:5173
  API_OPENAPI_URL: http://localhost:8000/api/v1/openapi.json
  DOCKER_BUILDKIT: "1"

defaults:
  run:
    shell: bash

jobs:
  sast_sca:
    name: SAST + SCA
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Prepare reports dir
        run: mkdir -p reports/sast reports/sca

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: |
            frontend/package-lock.json
            frontend/package.json

      # -------- SAST: Semgrep --------
      - name: Semgrep (SAST)
        continue-on-error: true
        uses: returntocorp/semgrep-action@v1
        with:
          config: |
            p/owasp-top-ten
            p/ci
          generateSarif: "1"

      - name: Upload Semgrep SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep.sarif

      - name: Collect Semgrep report
        if: always()
        run: |
          cp -f semgrep.sarif reports/sast/semgrep.sarif 2>/dev/null || true

      # -------- SAST: Bandit --------
      - name: Install Bandit
        continue-on-error: true
        run: pipx install bandit || pip install bandit

      - name: Run Bandit (backend)
        continue-on-error: true
        run: bandit -r backend -ll -iii -f json -o bandit.json

      - name: Collect Bandit report
        if: always()
        run: |
          cp -f bandit.json reports/sast/bandit.json 2>/dev/null || true

      # -------- SCA: Trivy (repo) -> SARIF --------
      - name: Trivy FS (SCA + misconfig + secrets)
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          scan-type: fs
          scan-ref: .
          ignore-unfixed: true
          severity: HIGH,CRITICAL
          format: sarif
          output: trivy-repo.sarif

      - name: Upload Trivy SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-repo.sarif

      - name: Collect Trivy SARIF
        if: always()
        run: |
          cp -f trivy-repo.sarif reports/sca/trivy-repo.sarif 2>/dev/null || true

      # -------- SBOM: Trivy (CycloneDX) --------
      - name: Trivy SBOM (CycloneDX)
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          scan-type: fs
          scan-ref: .
          args: --format cyclonedx --output sbom.cdx.json

      - name: Collect SBOM
        if: always()
        run: |
          cp -f sbom.cdx.json reports/sca/sbom.cyclonedx.json 2>/dev/null || true

      # -------- SCA: Python (pip-audit) --------
      - name: Install pip-audit
        continue-on-error: true
        run: pipx install pip-audit || pip install pip-audit

      - name: pip-audit (backend)
        continue-on-error: true
        run: |
          if [ -f backend/requirements.txt ]; then
            pip-audit -r backend/requirements.txt -f json -o pip-audit.json
          else
            echo '{}' > pip-audit.json
          fi

      - name: Collect pip-audit report
        if: always()
        run: |
          cp -f pip-audit.json reports/sca/pip-audit.json 2>/dev/null || true

      # -------- Frontend: lint + npm audit --------
      - name: Frontend install
        if: hashFiles('frontend/package.json') != ''
        continue-on-error: true
        working-directory: frontend
        run: npm ci

      - name: Frontend lint
        if: hashFiles('frontend/package.json') != ''
        continue-on-error: true
        working-directory: frontend
        run: npm run lint

      - name: npm audit (high+)
        if: hashFiles('frontend/package.json') != ''
        continue-on-error: true
        working-directory: frontend
        run: npm audit --audit-level=high --json > ../npm-audit.json

      - name: Collect npm-audit
        if: always() && hashFiles('frontend/package.json') != ''
        run: |
          cp -f npm-audit.json reports/sca/npm-audit.json 2>/dev/null || true

      # ---- Upload ONE artifact with everything from this job ----
      - name: Upload consolidated reports (SAST/SCA)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: reports/**
          if-no-files-found: ignore
          retention-days: 14

  build_and_dast:
    name: DAST (ZAP) — start app only for tests (Docker)
    runs-on: ubuntu-latest
    needs: [sast_sca]
    timeout-minutes: 45

    services:
      postgres:
        image: postgres:17
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: changethis
          POSTGRES_DB: app
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d app"
          --health-interval=10s --health-timeout=5s --health-retries=10

    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Prepare reports dir
        run: mkdir -p reports/dast

      # ---- ENV na czas DAST (zgodne z Pydantic v2 + brakujące pola) ----
      - name: Prepare runtime env
        run: |
          echo 'DOMAIN=localhost' >> $GITHUB_ENV
          echo 'FRONTEND_HOST=http://localhost:5173' >> $GITHUB_ENV
          echo 'ENVIRONMENT=local' >> $GITHUB_ENV
          echo 'BACKEND_CORS_ORIGINS=["http://localhost:5173","http://127.0.0.1:5173","http://localhost"]' >> $GITHUB_ENV
          echo 'SECRET_KEY=dev-secret' >> $GITHUB_ENV
          echo 'FIRST_SUPERUSER=admin@example.com' >> $GITHUB_ENV
          echo 'FIRST_SUPERUSER_PASSWORD=StrongPassw0rd!' >> $GITHUB_ENV
          echo 'PROJECT_NAME=app' >> $GITHUB_ENV
          # DB z service-containera via host-gateway
          echo 'POSTGRES_SERVER=host.docker.internal' >> $GITHUB_ENV
          echo 'POSTGRES_PORT=5432' >> $GITHUB_ENV
          echo 'POSTGRES_DB=app' >> $GITHUB_ENV
          echo 'POSTGRES_USER=postgres' >> $GITHUB_ENV
          echo 'POSTGRES_PASSWORD=changethis' >> $GITHUB_ENV
          echo 'SMTP_HOST=' >> $GITHUB_ENV
          echo 'SMTP_USER=' >> $GITHUB_ENV
          echo 'SMTP_PASSWORD=' >> $GITHUB_ENV
          echo 'EMAILS_FROM_EMAIL=info@example.com' >> $GITHUB_ENV
          echo 'SENTRY_DSN=' >> $GITHUB_ENV

      # ---- Backend: build + run z nadpisaną komendą (nasłuch z zewnątrz) ----
      - name: Build backend image
        if: hashFiles('backend/Dockerfile') != ''
        run: docker build -t backend-ci:latest ./backend

      - name: Run backend container
        if: hashFiles('backend/Dockerfile') != ''
        run: |
          docker run -d --name backend-ci \
            --add-host=host.docker.internal:host-gateway \
            -p 8000:8000 \
            -e DOMAIN="${DOMAIN}" \
            -e FRONTEND_HOST="${FRONTEND_HOST}" \
            -e ENVIRONMENT="${ENVIRONMENT}" \
            -e BACKEND_CORS_ORIGINS='${BACKEND_CORS_ORIGINS}' \
            -e SECRET_KEY="${SECRET_KEY}" \
            -e FIRST_SUPERUSER="${FIRST_SUPERUSER}" \
            -e FIRST_SUPERUSER_PASSWORD="${FIRST_SUPERUSER_PASSWORD}" \
            -e POSTGRES_SERVER="${POSTGRES_SERVER}" \
            -e POSTGRES_PORT="${POSTGRES_PORT}" \
            -e POSTGRES_DB="${POSTGRES_DB}" \
            -e POSTGRES_USER="${POSTGRES_USER}" \
            -e POSTGRES_PASSWORD="${POSTGRES_PASSWORD}" \
            -e SENTRY_DSN="${SENTRY_DSN}" \
            -e PROJECT_NAME="${PROJECT_NAME}" \
            backend-ci:latest \
            fastapi run app/main.py --host 0.0.0.0 --port 8000 --workers 4

      - name: Wait for backend health
        if: hashFiles('backend/Dockerfile') != ''
        run: |
          for i in {1..60}; do
            curl -fsS http://localhost:8000/api/v1/utils/health-check/ && exit 0
            sleep 2
          done
          echo "Backend not healthy"; docker logs backend-ci || true; exit 1

      # ---- Frontend: build + run (jeśli jest Dockerfile) ----
      - name: Build frontend image
        if: hashFiles('frontend/Dockerfile') != ''
        run: docker build --build-arg VITE_API_URL=http://localhost:8000 -t frontend-ci:latest ./frontend

      - name: Run frontend container
        if: hashFiles('frontend/Dockerfile') != ''
        run: |
          docker run -d --name frontend-ci \
            -p 5173:80 \
            frontend-ci:latest

      - name: Wait for frontend
        if: hashFiles('frontend/Dockerfile') != ''
        run: |
          for i in {1..60}; do
            curl -fsS ${{ env.FRONT_URL }} && exit 0
            sleep 2
          done
          echo "Frontend not responding"; docker logs frontend-ci || true; exit 1

      # ---- ZAP DAST ----
      - name: ZAP Baseline (frontend)
        if: hashFiles('frontend/Dockerfile') != ''
        run: |
          docker run --rm -t owasp/zap2docker-stable zap-baseline.py \
            -t "${{ env.FRONT_URL }}" \
            -m 10 \
            -r zap-frontend.html | tee zap-baseline.log

      - name: ZAP API Scan (backend OpenAPI)
        if: hashFiles('backend/Dockerfile') != ''
        run: |
          docker run --rm -t -u zap -v "$PWD:/zap/wrk" owasp/zap2docker-stable zap-api-scan.py \
            -t "${{ env.API_OPENAPI_URL }}" \
            -f openapi \
            -m 15 \
            -r zap-api.html | tee zap-api.log


      - name: Collect ZAP reports
        if: always()
        run: |
          mkdir -p reports/dast
          [ -f zap-frontend.html ] && cp -f zap-frontend.html reports/dast/zap-frontend.html || true
          [ -f zap-api.html ] && cp -f zap-api.html reports/dast/zap-api.html || true
          [ -f zap-baseline.log ] && cp -f zap-baseline.log reports/dast/zap-baseline.log || true
          [ -f zap-api.log ] && cp -f zap-api.log reports/dast/zap-api.log || true

      # ---- Sprzątanie: kontenery działały tylko na czas DAST ----
      - name: Teardown app containers
        if: always()
        run: |
          docker rm -f backend-ci 2>/dev/null || true
          docker rm -f frontend-ci 2>/dev/null || true

      # ---- Upload to the SAME artifact name (merge with SAST/SCA) ----
      - name: Upload consolidated reports (DAST)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: reports/**
          if-no-files-found: ignore
          retention-days: 14
